{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b628a52f-f8ec-4357-8af4-d89704579a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('real/US_REAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8324db2f-0b73-41f0-ae49-717a6d5b5ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol',\n",
       "       'Timestamp', 'Flow Duration', 'Total Fwd Packet', 'Total Bwd packets',\n",
       "       'Total Length of Fwd Packet', 'Total Length of Bwd Packet',\n",
       "       'Fwd Packet Length Max', 'Fwd Packet Length Min',\n",
       "       'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
       "       'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
       "       'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
       "       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
       "       'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
       "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
       "       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
       "       'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd RST Flags',\n",
       "       'Bwd RST Flags', 'Fwd Header Length', 'Bwd Header Length',\n",
       "       'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min',\n",
       "       'Packet Length Max', 'Packet Length Mean', 'Packet Length Std',\n",
       "       'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count',\n",
       "       'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count',\n",
       "       'CWR Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
       "       'Average Packet Size', 'Fwd Segment Size Avg', 'Bwd Segment Size Avg',\n",
       "       'Fwd Bytes/Bulk Avg', 'Fwd Packet/Bulk Avg', 'Fwd Bulk Rate Avg',\n",
       "       'Bwd Bytes/Bulk Avg', 'Bwd Packet/Bulk Avg', 'Bwd Bulk Rate Avg',\n",
       "       'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets',\n",
       "       'Subflow Bwd Bytes', 'FWD Init Win Bytes', 'Bwd Init Win Bytes',\n",
       "       'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n",
       "       'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max',\n",
       "       'Idle Min', 'ICMP Code', 'ICMP Type', 'Total TCP Flow Time', 'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a166010-78da-4694-819e-6deffcd2cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data = data.drop(columns=['Flow ID', 'Src IP', 'Timestamp', 'Dst IP', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4026ab9-1df9-409b-b173-bf605ebcf8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows and cols: (746, 84)\n",
      "\n",
      "Columns: Index(['Src Port', 'Dst Port', 'Protocol', 'Flow Duration', 'Total Fwd Packet',\n",
      "       'Total Bwd packets', 'Total Length of Fwd Packet',\n",
      "       'Total Length of Bwd Packet', 'Fwd Packet Length Max',\n",
      "       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
      "       'Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
      "       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
      "       'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s',\n",
      "       'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n",
      "       'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
      "       'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std',\n",
      "       'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags',\n",
      "       'Fwd URG Flags', 'Bwd URG Flags', 'Fwd RST Flags', 'Bwd RST Flags',\n",
      "       'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s',\n",
      "       'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max',\n",
      "       'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance',\n",
      "       'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count',\n",
      "       'ACK Flag Count', 'URG Flag Count', 'CWR Flag Count', 'ECE Flag Count',\n",
      "       'Down/Up Ratio', 'Average Packet Size', 'Fwd Segment Size Avg',\n",
      "       'Bwd Segment Size Avg', 'Fwd Bytes/Bulk Avg', 'Fwd Packet/Bulk Avg',\n",
      "       'Fwd Bulk Rate Avg', 'Bwd Bytes/Bulk Avg', 'Bwd Packet/Bulk Avg',\n",
      "       'Bwd Bulk Rate Avg', 'Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
      "       'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'FWD Init Win Bytes',\n",
      "       'Bwd Init Win Bytes', 'Fwd Act Data Pkts', 'Fwd Seg Size Min',\n",
      "       'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
      "       'Idle Std', 'Idle Max', 'Idle Min', 'ICMP Code', 'ICMP Type',\n",
      "       'Total TCP Flow Time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of rows and cols:\", us_data.shape)\n",
    "print(\"\\nColumns:\", us_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c585ce26-f021-46a5-bc35-dd759b2752fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow Bytes/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
       "       'Flow IAT Min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_data.columns[us_data.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "275d312c-11d6-4453-90ff-a9d70094afc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow Bytes/s     682\n",
       "Flow IAT Mean    682\n",
       "Flow IAT Std     682\n",
       "Flow IAT Max     682\n",
       "Flow IAT Min     682\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_data.isnull().sum()[us_data.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b61c16-2acc-4650-ae58-6318a6b451e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAIRAZEX\\AppData\\Local\\Temp\\ipykernel_19268\\385993871.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  us_data.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "us_data.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d234c12-4f84-44f9-893c-c3ee7be5d16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_data.columns[us_data.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96403756-4864-4e89-a382-ca28cf7006b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate rows in dataset: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total duplicate rows in dataset: {us_data.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8177f1bd-4abe-4f17-a02c-75f7c3a9f21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate rows in dataset: 0\n",
      "No. of rows and cols after removing duplicates:  (746, 84)\n"
     ]
    }
   ],
   "source": [
    "us_data = us_data.drop_duplicates()\n",
    "print(f\"Total duplicate rows in dataset: {us_data.duplicated().sum()}\")\n",
    "print(\"No. of rows and cols after removing duplicates: \", us_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "188655f0-da24-4837-8828-759b3e44d2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Using cached catboost-1.2.7.tar.gz (71.5 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  pip subprocess to install build dependencies did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [147 lines of output]\n",
      "  Collecting setuptools>=64.0\n",
      "    Using cached setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Collecting wheel\n",
      "    Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Collecting jupyterlab==3.*,>=3.0.6\n",
      "    Using cached jupyterlab-3.6.8-py3-none-any.whl.metadata (12 kB)\n",
      "  Collecting conan~=1.62\n",
      "    Using cached conan-1.66.0.tar.gz (789 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Collecting ipython (from jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached ipython-9.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "  Collecting packaging (from jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Collecting tornado>=6.1.0 (from jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached tornado-6.4.2-cp38-abi3-win_amd64.whl.metadata (2.6 kB)\n",
      "  Collecting jupyter-core (from jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Collecting jupyterlab-server~=2.19 (from jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Collecting jupyter-server<3,>=1.16.0 (from jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
      "  Collecting jupyter-ydoc~=0.2.4 (from jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached jupyter_ydoc-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Collecting jupyter-server-ydoc~=0.8.0 (from jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached jupyter_server_ydoc-0.8.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "  Collecting nbclassic (from jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached nbclassic-1.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Collecting notebook<7 (from jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached notebook-6.5.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Collecting jinja2>=2.1 (from jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Collecting requests<3.0.0,>=2.25 (from conan~=1.62)\n",
      "    Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Collecting urllib3<1.27,>=1.26.6 (from conan~=1.62)\n",
      "    Using cached urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "  Collecting colorama<0.5.0,>=0.3.3 (from conan~=1.62)\n",
      "    Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "  Collecting PyYAML<6.1,>=3.11 (from conan~=1.62)\n",
      "    Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "  Collecting patch-ng<1.18,>=1.17.4 (from conan~=1.62)\n",
      "    Using cached patch-ng-1.17.4.tar.gz (17 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Collecting fasteners>=0.14.1 (from conan~=1.62)\n",
      "    Using cached fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Collecting six<=1.16.0,>=1.10.0 (from conan~=1.62)\n",
      "    Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "  Collecting node-semver==0.6.1 (from conan~=1.62)\n",
      "    Using cached node_semver-0.6.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Collecting pygments<3.0,>=2.0 (from conan~=1.62)\n",
      "    Using cached pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Collecting tqdm<5,>=4.28.1 (from conan~=1.62)\n",
      "    Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "  Collecting python-dateutil<3,>=2.7.0 (from conan~=1.62)\n",
      "    Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "  Collecting bottle<0.13,>=0.12.8 (from conan~=1.62)\n",
      "    Using cached bottle-0.12.25-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Collecting pluginbase>=0.5 (from conan~=1.62)\n",
      "    Using cached pluginbase-1.0.1.tar.gz (43 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Collecting PyJWT<3.0.0,>=2.4.0 (from conan~=1.62)\n",
      "    Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "  Collecting MarkupSafe>=2.0 (from jinja2>=2.1->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "  Collecting anyio>=3.1.0 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "  Collecting jupyter-client>=7.4.4 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "  Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "  Collecting nbconvert>=6.4.4 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Collecting nbformat>=5.3.0 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "  Collecting overrides>=5.0 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Collecting prometheus-client>=0.9 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Collecting pywinpty>=2.0.1 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached pywinpty-2.0.15-cp313-cp313-win_amd64.whl.metadata (5.2 kB)\n",
      "  Collecting pyzmq>=24 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached pyzmq-26.4.0-cp313-cp313-win_amd64.whl.metadata (6.0 kB)\n",
      "  Collecting send2trash>=1.8.2 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "  Collecting terminado>=0.8.3 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Collecting traitlets>=5.6.0 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "  Collecting websocket-client>=1.7 (from jupyter-server<3,>=1.16.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "  Collecting platformdirs>=2.5 (from jupyter-core->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached platformdirs-4.3.7-py3-none-any.whl.metadata (11 kB)\n",
      "  Collecting pywin32>=300 (from jupyter-core->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached pywin32-310-cp313-cp313-win_amd64.whl.metadata (9.4 kB)\n",
      "  Collecting jupyter-server-fileid<1,>=0.6.0 (from jupyter-server-ydoc~=0.8.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached jupyter_server_fileid-0.9.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Collecting ypy-websocket<0.9.0,>=0.8.2 (from jupyter-server-ydoc~=0.8.0->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached ypy_websocket-0.8.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Collecting y-py<0.7.0,>=0.6.0 (from jupyter-ydoc~=0.2.4->jupyterlab==3.*,>=3.0.6)\n",
      "    Using cached y_py-0.6.2.tar.gz (53 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "    error: subprocess-exited-with-error\n",
      "  \n",
      "    Preparing metadata (pyproject.toml) did not run successfully.\n",
      "    exit code: 1\n",
      "  \n",
      "    [6 lines of output]\n",
      "  \n",
      "    Cargo, the Rust package manager, is not installed or is not on PATH.\n",
      "    This package requires Rust and Cargo to compile extensions. Install it through\n",
      "    the system's package manager or via https://rustup.rs/\n",
      "  \n",
      "    Checking for Rust toolchain....\n",
      "    [end of output]\n",
      "  \n",
      "    note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  error: metadata-generation-failed\n",
      "  \n",
      "  Encountered error while generating package metadata.\n",
      "  \n",
      "  See above for output.\n",
      "  \n",
      "  note: This is an issue with the package mentioned above, not pip.\n",
      "  hint: See above for details.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "pip subprocess to install build dependencies did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "529d0678-85c1-447e-9dd4-aa27ccf6bbf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[32m      5\u001b[39m model_filename = \u001b[33m'\u001b[39m\u001b[33mStackingEnsemble.joblib\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m loaded_model = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# List of features in the order required by the model\u001b[39;00m\n\u001b[32m      9\u001b[39m feature_order = [\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mRST Flag Count\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mFwd Packet Length Max\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mSubflow Bwd Bytes\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     30\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode)\u001b[39m\n\u001b[32m    652\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    653\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    654\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    655\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[32m    656\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m             obj = \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[39m, in \u001b[36m_unpickle\u001b[39m\u001b[34m(fobj, filename, mmap_mode)\u001b[39m\n\u001b[32m    575\u001b[39m obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m     obj = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m unpickler.compat_mode:\n\u001b[32m    579\u001b[39m         warnings.warn(\u001b[33m\"\u001b[39m\u001b[33mThe file \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has been generated with a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m                       \u001b[33m\"\u001b[39m\u001b[33mjoblib version less than 0.10. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m                       \u001b[33m\"\u001b[39m\u001b[33mPlease regenerate this pickle file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m                       % filename,\n\u001b[32m    583\u001b[39m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\pickle.py:1256\u001b[39m, in \u001b[36m_Unpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1254\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[32m   1258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\pickle.py:1581\u001b[39m, in \u001b[36m_Unpickler.load_stack_global\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m   1580\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[33m\"\u001b[39m\u001b[33mSTACK_GLOBAL requires str\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1581\u001b[39m \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\pickle.py:1622\u001b[39m, in \u001b[36m_Unpickler.find_class\u001b[39m\u001b[34m(self, module, name)\u001b[39m\n\u001b[32m   1620\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle.IMPORT_MAPPING:\n\u001b[32m   1621\u001b[39m         module = _compat_pickle.IMPORT_MAPPING[module]\n\u001b[32m-> \u001b[39m\u001b[32m1622\u001b[39m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.proto >= \u001b[32m4\u001b[39m:\n\u001b[32m   1624\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys.modules[module], name)[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the model\n",
    "model_filename = 'StackingEnsemble.joblib'\n",
    "loaded_model = joblib.load(model_filename)\n",
    "\n",
    "# List of features in the order required by the model\n",
    "feature_order = [\n",
    "    'RST Flag Count', \n",
    "    'Fwd Packet Length Max', \n",
    "    'Packet Length Std',\n",
    "    'Total Length of Fwd Packet', \n",
    "    'Packet Length Variance', \n",
    "    'Flow Bytes/s',\n",
    "    'Fwd Packet Length Mean', \n",
    "    'FIN Flag Count', \n",
    "    'Packet Length Max',\n",
    "    'Fwd RST Flags', \n",
    "    'Fwd Segment Size Avg', \n",
    "    'Packet Length Mean',\n",
    "    'Bwd Packet Length Std', \n",
    "    'Average Packet Size', \n",
    "    'Bwd Segment Size Avg',\n",
    "    'Bwd RST Flags', \n",
    "    'Bwd Packet Length Max', \n",
    "    'Flow IAT Mean',\n",
    "    'Bwd Packet Length Mean', \n",
    "    'Subflow Bwd Bytes'\n",
    "]\n",
    "\n",
    "# Extract the relevant features for prediction\n",
    "X = us_data[feature_order]\n",
    "\n",
    "# Run prediction\n",
    "predictions = loaded_model.predict(X)\n",
    "\n",
    "# Save predictions as a new DataFrame column\n",
    "predict_df = pd.DataFrame(predictions, columns=['Predicted'])\n",
    "\n",
    "# Concatenate predictions with original data\n",
    "predict_df = pd.concat([us_data.reset_index(drop=True), predict_df], axis=1)\n",
    "\n",
    "# Save to CSV\n",
    "predict_df.to_csv('datasets/usdata_stack.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to datasets/usdata_stack.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a6933e-1084-480a-a656-1f4dd3bfb800",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"BENIGN\": 0,\n",
    "    \"Portscan\": 1,\n",
    "    \"DDoS\": 2,\n",
    "    \"Web Attack - Brute Force\": 3\n",
    "}\n",
    "\n",
    "# Step 3: Map actual labels to numerical format\n",
    "us_data['Label'] = data['Label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99dd467-aa10-4921-a01d-578ff6146e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81731c72-e6ca-4e8f-8c61-8bb73a4eb2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "predicted_df = pd.read_csv('datasets/usdata_stack.csv')\n",
    "\n",
    "y_true = us_data['Label']              # Adjust if label column is named differently\n",
    "y_pred = predicted_df['Predicted']  \n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7ba571-085b-4246-acce-e7097c5144e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''!pip install --force-reinstall --no-deps matplotlib==3.7.1'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388d603-5df0-4da2-9842-38d65f31ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([1, 2, 3], [4, 5, 6])\n",
    "plt.title(\"✅ Matplotlib Fixed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf94a2-9110-4d0b-bafa-a82f70a59710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predicted_df = predicted_df.reset_index(drop=True)\n",
    "labels_df = labels_df.reset_index(drop=True)\n",
    "\n",
    "y_true = us_data['Label']\n",
    "y_pred = predicted_df['Predicted']\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[0, 1, 2, 3],\n",
    "            yticklabels=[0, 1, 2, 3])\n",
    "plt.title('Confusion Matrix Heatmap (4-Class)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07416158-c16c-4160-870e-029d313b7ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
